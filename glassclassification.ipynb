{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e78462",
   "metadata": {},
   "source": [
    "# Glass Classification Notebook\n",
    "\n",
    "_Converted automatically from `glassclassification.py` on 2025-08-25 02:55:50_\n",
    "\n",
    "> Note: This notebook preserves your original script in a single code cell below. \n",
    "You can split it into multiple cells later if you like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b532c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#importing the dataset\n",
    "df=pd.read_csv('glass.csv')\n",
    "print(df.head())\n",
    "\n",
    "df.info()\n",
    "print(df.columns)\n",
    "print(df.values)\n",
    "print(df.index)\n",
    "\n",
    "#data cleaning\n",
    "#count number of missing values in each columns\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#drop rows with missing values\n",
    "df=df.dropna(axis=0)\n",
    "\n",
    "#Data Exploration\n",
    "print(df.describe())\n",
    "\n",
    "#df.hist()\n",
    "df.boxplot()\n",
    "plt.show()\n",
    "df.hist()\n",
    "plt.show()\n",
    "plt.figure(figsize= (10,7))\n",
    "sns.heatmap(df.corr(), annot = True, fmt= ' .1g')\n",
    "plt.show()\n",
    "\n",
    "#splitting the dataset in independent and dependent variables\n",
    "X=df.iloc[:,:9]\n",
    "y=df['Type']\n",
    "\n",
    "#splitting the dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "\n",
    "#rc = BaggingClassifier(DecisionTreeClassifier(),n_estimators = 5)\n",
    "#rc =AdaBoostClassifier(n_estimators=15,learning_rate=1)\n",
    "#rc = GradientBoostingClassifier(max_depth=2,n_estimators =50,learning_rate=1.0)\n",
    "rc = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "rc.fit(X_train, y_train)\n",
    "y_pred = rc.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}